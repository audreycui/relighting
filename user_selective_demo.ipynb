{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "taken-riverside",
   "metadata": {},
   "source": [
    "# Relighting a real image with user selection\n",
    "This notebook loads an interactivate demo for our user selective relighting method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stuffed-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, inspect\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir) \n",
    "\n",
    "from options.test_options import TestOptions\n",
    "from data.data_loader import CreateDataLoader\n",
    "from models.models import create_model\n",
    "\n",
    "from importlib import reload\n",
    "from rewrite_utils import zdataset, show, labwidget, paintwidget, renormalize, nethook, imgviz, pbar, smoothing\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8114d10",
   "metadata": {},
   "source": [
    "We first load the relighting model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affiliated-democrat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "aspect_ratio: 1.0\n",
      "batchSize: 1\n",
      "checkpoints_dir: ./checkpoints\n",
      "cluster_path: features_clustered_010.npy\n",
      "data_type: 32\n",
      "dataroot: ./datasets/cityscapes/\n",
      "debug: False\n",
      "display_winsize: 512\n",
      "engine: None\n",
      "export_onnx: None\n",
      "feat_num: 3\n",
      "fineSize: 512\n",
      "fp16: False\n",
      "frac_neg_one: False\n",
      "frac_one: False\n",
      "generated: False\n",
      "gpu_ids: [0]\n",
      "how_many: 50\n",
      "input_nc: 3\n",
      "instance_feat: False\n",
      "isTrain: False\n",
      "label_feat: False\n",
      "label_nc: 0\n",
      "linspace_off: False\n",
      "linspace_on: False\n",
      "loadSize: 1024\n",
      "load_features: False\n",
      "local_rank: 0\n",
      "masked: False\n",
      "max_dataset_size: inf\n",
      "model: pix2pixHD\n",
      "nThreads: 2\n",
      "n_blocks_global: 9\n",
      "n_blocks_local: 3\n",
      "n_clusters: 10\n",
      "n_downsample_E: 4\n",
      "n_downsample_global: 4\n",
      "n_local_enhancers: 1\n",
      "n_stylechannels: 1\n",
      "name: selective\n",
      "nef: 16\n",
      "netG: modulated\n",
      "ngf: 64\n",
      "niter_fix_global: 0\n",
      "no_flip: False\n",
      "no_instance: False\n",
      "norm: instance\n",
      "ntest: inf\n",
      "onnx: None\n",
      "output_nc: 3\n",
      "phase: test\n",
      "resize_or_crop: scale_width\n",
      "results_dir: ./results/\n",
      "serial_batches: False\n",
      "tf_log: False\n",
      "use_dropout: False\n",
      "use_encoded_image: False\n",
      "verbose: False\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "padding type reflect\n",
      "ModulatedGenerator(\n",
      "  (initial_block): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(4, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (downsample_blocks): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (7): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (10): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (11): ReLU(inplace=True)\n",
      "  )\n",
      "  (resnet_blocks): ModuleList(\n",
      "    (0): ModulatedResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "      (scalar_to_style): Linear(in_features=1, out_features=1024, bias=True)\n",
      "    )\n",
      "    (1): ModulatedResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "      (scalar_to_style): Linear(in_features=1, out_features=1024, bias=True)\n",
      "    )\n",
      "    (2): ModulatedResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "      (scalar_to_style): Linear(in_features=1, out_features=1024, bias=True)\n",
      "    )\n",
      "    (3): ModulatedResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "      (scalar_to_style): Linear(in_features=1, out_features=1024, bias=True)\n",
      "    )\n",
      "    (4): ModulatedResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "      (scalar_to_style): Linear(in_features=1, out_features=1024, bias=True)\n",
      "    )\n",
      "    (5): ModulatedResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "      (scalar_to_style): Linear(in_features=1, out_features=1024, bias=True)\n",
      "    )\n",
      "    (6): ModulatedResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "      (scalar_to_style): Linear(in_features=1, out_features=1024, bias=True)\n",
      "    )\n",
      "    (7): ModulatedResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "      (scalar_to_style): Linear(in_features=1, out_features=1024, bias=True)\n",
      "    )\n",
      "    (8): ModulatedResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "      (scalar_to_style): Linear(in_features=1, out_features=1024, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (upsample_blocks): Sequential(\n",
      "    (0): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (7): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (10): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (11): ReLU(inplace=True)\n",
      "  )\n",
      "  (output_block): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): Tanh()\n",
      "  )\n",
      ")\n",
      "save_filename latest_net_G.pth\n",
      "save_dir ./checkpoints/selective\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed locating file data/0: file not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_949/627839634.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/relight/models/models.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mui_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUIModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUIModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model [%s] was created\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/relight/models/pix2pixHD_model.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misTrain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinue_train\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_pretrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mpretrained_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misTrain\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_pretrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'G'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhich_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misTrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhich_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/relight/models/base_model.py\u001b[0m in \u001b[0;36mload_network\u001b[0;34m(self, network, network_label, epoch_label, save_dir)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pbenv/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pbenv/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pbenv/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pbenv/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed locating file data/0: file not found"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "cmd = ('--name selective '\n",
    "       '--netG modulated ' \n",
    "       '--input_nc 3 ' \n",
    "       '--label_nc 0 ' \n",
    "      ).split()\n",
    "\n",
    "opt = TestOptions().parse(save=False, cmd=cmd)\n",
    "model = create_model(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb89db",
   "metadata": {},
   "source": [
    "Load an image to be relit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f0175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load image\n",
    "import torchvision.transforms as transforms\n",
    "from data.base_dataset import __scale_width\n",
    "transforms = transforms.Compose([transforms.Lambda(lambda img: __scale_width(img, opt.loadSize)), \n",
    "              transforms.ToTensor(),\n",
    "              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "#insert path to your image here\n",
    "img_path = 'test_images/lsunbedroom.webp'\n",
    "\n",
    "dims = (256, 256)\n",
    "image = Image.open(img_path).resize(dims, Image.BILINEAR)\n",
    "show(image)\n",
    "baseline = transforms(image.convert('RGB'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85af75a0",
   "metadata": {},
   "source": [
    "Mask the region containing the light source that you would like to relight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-problem",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pw = paintwidget.PaintWidget(image=renormalize.as_url(baseline))\n",
    "def do_reset():\n",
    "    pw.mask = ''\n",
    "reset_btn = labwidget.Button('reset').on('click', do_reset)\n",
    "show([pw, reset_btn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get and threshold mask\n",
    "mask = renormalize.from_url(pw.mask, target='pt', size=baseline.shape[1:])[0]\n",
    "mask[mask>0.5] =1\n",
    "mask[mask<=0.5] =0\n",
    "mask = mask\n",
    "show(renormalize.as_image(mask[None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#blur mask - blurring the mask gives us realistic edits\n",
    "sigma = float(1024) / 16.0\n",
    "kernel_size = (int(sigma) * 2 - 1)\n",
    "blur = smoothing.GaussianSmoothing(1, kernel_size, sigma=sigma)\n",
    "mask_ = blur(mask[None, None])\n",
    "show(renormalize.as_image(mask_[0].repeat(3, 1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize mask on original image\n",
    "mask_copy = torch.clone(mask_)\n",
    "mask_img = mask_copy[None]#.repeat(3, 1, 1)\n",
    "\n",
    "temp = torch.clone(mask_copy)\n",
    "temp[temp>0] = torch.max(baseline)\n",
    "temp3 = torch.zeros(temp.shape)\n",
    "temp2 = [temp3, temp3, temp]\n",
    "temp2 = torch.stack(temp2)\n",
    "show(renormalize.as_image(baseline*(1-mask_img)+ temp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf832db",
   "metadata": {},
   "source": [
    "Control the relighting intensity (and color :)) using the sliders. Widgets originally implemented in https://github.com/davidbau/rewriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#widget for controlling selected light source\n",
    "\n",
    "reload(labwidget)\n",
    "lamp = labwidget.Range()\n",
    "im = labwidget.Image()\n",
    "lc = labwidget.ColorPicker('#ffffff', desc='lamp light color: ')\n",
    "\n",
    "\n",
    "show([['lamp intensity', lamp, lc, im]])\n",
    "\n",
    "\n",
    "def get_lit_scene(image, frac):\n",
    "    generated = model.inference(image.unsqueeze(0), mask_, amount=frac)\n",
    "    return generated\n",
    "\n",
    "im.render(renormalize.as_image(baseline))\n",
    "\n",
    "def readcolor(value):\n",
    "    try:\n",
    "        floatcolor = [float(int(value[i:i+2], 16))/255.0  for i in [1,3,5]]\n",
    "        color = torch.tensor(floatcolor).float()\n",
    "        #print('color', color)\n",
    "        if len(color) == 3:\n",
    "            return color\n",
    "    except:\n",
    "        pass\n",
    "    return torch.tensor([1.0, 1.0, 1.0]).float()\n",
    "\n",
    "def newimage():\n",
    "    def norm_value(vals): \n",
    "        return np.array([(float(val) * 2 - 100) / 100.0 for val in vals])\n",
    "        \n",
    "    lit_lamp = get_lit_scene(baseline, norm_value([lamp.value])).cpu()\n",
    "    \n",
    "    lamp_light = lit_lamp - baseline\n",
    "    \n",
    "    lamp_color = readcolor(lc.value)[:,None,None]\n",
    "    \n",
    "    colored = baseline + (lamp_light * lamp_color) \n",
    "    im.render(renormalize.as_image(colored[0]))\n",
    "\n",
    "lamp.on('value', newimage)\n",
    "#lamp_color.on('value', newimage)\n",
    "lc.on('value', newimage)\n",
    "None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
