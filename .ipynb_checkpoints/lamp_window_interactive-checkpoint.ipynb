{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relighting a Real Bedroom Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, inspect\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir) \n",
    "\n",
    "from options.test_options import TestOptions\n",
    "from data.data_loader import CreateDataLoader\n",
    "from models.models import create_model\n",
    "\n",
    "from importlib import reload\n",
    "from pbw_utils import zdataset, show, labwidget, paintwidget, renormalize, nethook, imgviz, pbar\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "cmd = ('--name alternate_train_lamp '\n",
    "       '--netG modulated --no_instance ' \n",
    "       '--input_nc 3 ' \n",
    "       '--label_nc 0 ' \n",
    "       '--dataroot /datasets/agata_light_all/ ' \n",
    "       '--which_epoch 500 ').split()\n",
    "\n",
    "opt = TestOptions().parse(save=False, cmd=cmd)\n",
    "model = create_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load image\n",
    "import torchvision.transforms as transforms\n",
    "from data.base_dataset import __scale_width\n",
    "transforms = transforms.Compose([transforms.Lambda(lambda img: __scale_width(img, opt.loadSize)), \n",
    "              transforms.ToTensor(),\n",
    "              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "#img_path = 'datasets/lsun_bedrooms/test_A/00000089629ce3ba87bae003073896ba01988dee.webp'\n",
    "#img_path = 'datasets/bedrooms/test_A/golden_bedroom.png'\n",
    "#img_path = 'datasets/bedrooms/test_A/window_lamp_3.jpeg'\n",
    "#img_path = 'datasets/bedrooms/test_A/wa309_1.jpg'\n",
    "#img_path = 'datasets/night_photos/test_A/fans5.png'\n",
    "img_path = 'datasets/night_photos/test_A/PXL_20211112_002705966.jpg'\n",
    "image = Image.open(img_path).resize((1024, 816), Image.BILINEAR)\n",
    "show(image)\n",
    "print(image.size)\n",
    "baseline = transforms(image.convert('RGB'))\n",
    "print(baseline.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#widget for controlling lamps and windows\n",
    "print(opt.name)\n",
    "reload(labwidget)\n",
    "lamp = labwidget.Range()\n",
    "window = labwidget.Range()\n",
    "im = labwidget.Image()\n",
    "lc = labwidget.ColorPicker('#ffffff', desc='lamp light color: ')\n",
    "wc = labwidget.ColorPicker('#ffffff', desc='window light color: ')\n",
    "\n",
    "# #num.value = image_number\n",
    "# lay.value = 'layer8'\n",
    "# uni.value = 397\n",
    "\n",
    "#show([['lamp intensity', lamp, '', 'window intensity', window, im]])\n",
    "show([['lamp intensity', lamp, lc, 'window intensity', window, wc, im]])\n",
    "#show([['lamp intensity', lamp, 'window intensity', window, window_color, im]])\n",
    "\n",
    "#change to forward pass of pix2pix\n",
    "#self.units = [265, 397] [lamp, window]\n",
    "#amount is a list \n",
    "def get_lit_scene(image, frac):\n",
    "    generated = model.inference(image.unsqueeze(0), None, None, amount=[frac[0]])\n",
    "    return generated\n",
    "\n",
    "#baseline = get_lit_scene(image, [-1.0, -1.0])\n",
    "im.render(renormalize.as_image(baseline))\n",
    "\n",
    "def readcolor(value):\n",
    "    try:\n",
    "        floatcolor = [float(int(value[i:i+2], 16))/255.0  for i in [1,3,5]]\n",
    "        color = torch.tensor(floatcolor).float()\n",
    "        #print('color', color)\n",
    "        if len(color) == 3:\n",
    "            return color\n",
    "    except:\n",
    "        pass\n",
    "    return torch.tensor([1.0, 1.0, 1.0]).float()\n",
    "\n",
    "def newimage():\n",
    "    def norm_value(vals): \n",
    "        return np.array([(float(val) * 2 - 100) / 100.0 for val in vals])\n",
    "    \n",
    "    #frac = norm_value([lamp.value, window.value])\n",
    "    print(norm_value([lamp.value, 50]))\n",
    "    lit_lamp = get_lit_scene(baseline, norm_value([lamp.value, 50])).cpu()\n",
    "    lit_window = get_lit_scene(baseline, norm_value([50, window.value])).cpu()\n",
    "    \n",
    "    lamp_light = lit_lamp - baseline\n",
    "    window_light = lit_window - baseline\n",
    "    \n",
    "    window_color = readcolor(wc.value)[:,None,None]\n",
    "    lamp_color = readcolor(lc.value)[:,None,None]\n",
    "    \n",
    "    colored = baseline + (lamp_light * lamp_color) + (window_light * window_color)\n",
    "    im.render(renormalize.as_image(colored[0]))\n",
    "\n",
    "lamp.on('value', newimage)\n",
    "window.on('value', newimage)\n",
    "#lamp_color.on('value', newimage)\n",
    "wc.on('value', newimage)\n",
    "lc.on('value', newimage)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one channel\n",
    "\n",
    "#widget for controlling lamps and windows\n",
    "\n",
    "reload(labwidget)\n",
    "lamp = labwidget.Range()\n",
    "im = labwidget.Image()\n",
    "lc = labwidget.ColorPicker('#ffffff', desc='lamp light color: ')\n",
    "\n",
    "# #num.value = image_number\n",
    "# lay.value = 'layer8'\n",
    "# uni.value = 397\n",
    "\n",
    "#show([['lamp intensity', lamp, '', 'window intensity', window, im]])\n",
    "show([['lamp intensity', lamp, lc, im]])\n",
    "#show([['lamp intensity', lamp, 'window intensity', window, window_color, im]])\n",
    "\n",
    "#change to forward pass of pix2pix\n",
    "#self.units = [265, 397] [lamp, window]\n",
    "#amount is a list \n",
    "def get_lit_scene(image, frac):\n",
    "    generated = model.inference(image.unsqueeze(0), None, None, amount=frac)\n",
    "    return generated\n",
    "\n",
    "#baseline = get_lit_scene(image, [-1.0, -1.0], lay.value, uni.value)\n",
    "im.render(renormalize.as_image(baseline))\n",
    "\n",
    "def readcolor(value):\n",
    "    try:\n",
    "        floatcolor = [float(int(value[i:i+2], 16))/255.0  for i in [1,3,5]]\n",
    "        color = torch.tensor(floatcolor).float()\n",
    "        #print('color', color)\n",
    "        if len(color) == 3:\n",
    "            return color\n",
    "    except:\n",
    "        pass\n",
    "    return torch.tensor([1.0, 1.0, 1.0]).float()\n",
    "\n",
    "def newimage():\n",
    "    def norm_value(vals): \n",
    "        return np.array([(float(val) * 2.5 - 100) / 100.0 for val in vals])\n",
    "    \n",
    "    #frac = norm_value([lamp.value, window.value])\n",
    "    lit_lamp = get_lit_scene(baseline, norm_value([lamp.value])).cpu()\n",
    "    lit_lamp \n",
    "    lamp_light = lit_lamp - baseline\n",
    " \n",
    "    lamp_color = readcolor(lc.value)[:,None,None]\n",
    "    \n",
    "    colored = baseline + (lamp_light * lamp_color)\n",
    "    im.render(renormalize.as_image(colored[0]))\n",
    "\n",
    "lamp.on('value', newimage)\n",
    "lc.on('value', newimage)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}